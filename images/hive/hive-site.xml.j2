<configuration>
    <!-- see https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties -->

    <!-- Hive Configuration can either be stored in this file or in the hadoop configuration files  -->
    <!-- that are implied by Hadoop setup variables.                                                -->
    <!-- Aside from Hadoop setup variables - this file is provided as a convenience so that Hive    -->
    <!-- users do not have to edit hadoop configuration files (that may be managed as a centralized -->
    <!-- resource).                                                                                 -->


    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- Hive Metastore -->

    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
        <description>Location of default database for the warehouse</description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:derby:;databaseName=/var/lib/hive/metastore/metastore_db;create=true</value>
        <description>JDBC connect string for a JDBC metastore</description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.apache.derby.jdbc.EmbeddedDriver</value>
        <description>Driver class name for a JDBC metastore</description>
    </property>

    


    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- Transactions and Compactor       -->
    <!-- See https://www.cloudera.com/documentation/enterprise/5-15-x/topics/cdh_ig_hiveserver2_configure.html#topic_18_5_1 -->
    <property>
        <name>hive.support.concurrency</name>
        <value>false</value>        
        <description>Whether hive supports concurrency or not. A zookeeper instance must be up and running for the default hive lock manager to support read-write locks.</description>
    </property>



    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- HiveServer2                      -->

    <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
        <description>TCP port number to listen on, default 10000</description>
    </property>



    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- Query and DDL Execution          -->
    
    <property>
        <name>hive.execution.engine</name>
        <value>mr</value>
        <description>Chooses execution engine. Options are: mr (Map Reduce, default), tez (Tez execution, for Hadoop 2 only), or spark (Spark execution, for Hive 1.1.0 onward).</description>
    </property>
    
</configuration>