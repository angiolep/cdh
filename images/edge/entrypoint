#!/usr/bin/env bash

#
# Setup user accounts with proper ~/.bash_profile
#
chmod +x /etc/docker/setup
# --------------   user   group   domain
/etc/docker/setup  alice  hadoop
/etc/docker/setup  david  hadoop



#
# Render configuration templates by replacing {{ PLACEHOLDER }}
# with corresponding shell environment variable values
#
chmod +x /etc/docker/render
/etc/docker/render  /etc/hadoop/conf/core-site.xml
/etc/docker/render  /etc/hadoop/conf/hdfs-site.xml
/etc/docker/render  /etc/hadoop/conf/mapred-site.xml
/etc/docker/render  /etc/hadoop/conf/yarn-site.xml
# TODO /etc/docker/render  /etc/hadoop/conf/hive-site.xml


# Wait until both namenode and datanode services are available
while ! echo exit | nc namenode.docker.net 8020; do sleep 10; done
# TODO while ! echo exit | nc datanode1.docker.net 1004; do sleep 10; done
# TODO careful with port number 1004


su - alice <<'EOF'
hadoop fs -mkdir -p /data/raw
hadoop fs -chmod -R 775 /data
hadoop fs -copyFromLocal -f /var/data/raw/titanic.csv /data/raw
EOF


# Publish the Hadoop configuration through the shared /conf directory
files="core-site.xml hdfs-site.xml mapred-site.xml yarn-site.xml"
for file in $files; do
  cp /etc/hadoop/conf/$file /shared
done

# Publish the Kerberos configuration too
cp /etc/krb5.conf /shared


# Start the SSH deamon service
service sshd start

# Keep this container running
/etc/docker/idle
