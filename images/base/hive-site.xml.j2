<configuration>
    <!-- see https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties -->

    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- Hive Metastore in Embedded Mode  -->
    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>/user/hive/warehouse</value>
        <description>Location of default database for the warehouse</description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:derby:;databaseName=/var/lib/hive/metastore/metastore_db;create=true</value>
        <description>JDBC connect string from a JDBC metastore</description>
    </property>

    <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.apache.derby.jdbc.EmbeddedDriver</value>
        <description>Driver class name from a JDBC metastore</description>
    </property>


    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- Transactions and Compactor       -->
    <!-- See https://www.cloudera.com/documentation/enterprise/5-15-x/topics/cdh_ig_hiveserver2_configure.html#topic_18_5_1 -->
    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!--
      Whether hive supports concurrency or not.
      A zookeeper instance must be up and running for the
      default hive lock manager to support read-write locks.
    -->
    <property>
        <name>hive.support.concurrency</name>
        <value>false</value>
    </property>


    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- HiveServer2                      -->
    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!--
      TCP port number to listen on, default 10000
    -->
    <property>
        <name>hive.server2.thrift.port</name>
        <value>10000</value>
    </property>


    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- Query and DDL Execution          -->
    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!--
      Chooses data processing engine. Options are:
        * mr (Map Reduce, default),
        * tez (Tez execution, for Hadoop 2 only),
        * spark (Spark execution, for Hive 1.1.0 onward)
    -->
    <property>
        <name>hive.execution.engine</name>
        <value>mr</value>
    </property>



    {% if TLS_ENCRYPTION == 'true' %}
    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- TLS/SSL Encryption               -->
    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <property>
      <name>hive.server2.use.SSL</name>
      <value>true</value>
    </property>

    <property>
      <name>hive.server2.keystore.path</name>
      <value>${java.home}/lib/security/keystore.jks</value>
      <!-- NOTE that ${java.home} will be evaluated as "$JAVA_HOME/jre" -->
    </property>

    <property>
      <name>hive.server2.keystore.password</name>
      <value>changeit</value>
    </property>
    {% endif %}


    {% if HADOOP_AUTHENTICATION == 'kerberos' %}
    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!-- Kerberos Authentication          -->
    <!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
    <!--
      It is a client-facing property that controls the type of authentication
      HiveServer2 uses for connections to clients. In this case, HiveServer2
      uses Kerberos to authenticate incoming clients.
    -->
    <property>
      <name>hive.server2.authentication</name>
      <value>KERBEROS</value>
    </property>

    <!--
      It is the Kerberos principal for the host where HiveServer2 is running.
    -->
    <property>
      <name>hive.server2.authentication.kerberos.principal</name>
      <value>hive/docker.net@DOCKER.NET</value>
    </property>

    <!--
      It is the keytab file for that principal.
    -->
    <property>
      <name>hive.server2.authentication.kerberos.keytab</name>
      <value>/mount/secrets/hive.keytab</value>
    </property>

    <!--
      Enable user impersonation for HiveServer2 to let users execute queries
      and access HDFS files as the connected user rather than as the hive user.
    -->
    <property>
      <name>hive.server2.enable.impersonation</name>
      <value>true</value>
    </property>
    <property>
      <name>hive.server2.enable.doAs</name>
      <value>true</value>
    </property>
    {% endif %}

</configuration>
